{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitcefaae51de97494c8b3e896cae0342ea",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dados com Python 3 - Parte 2\n",
    "\n",
    "Autor: Rodolfo Bolconte Donato - https://github.com/rodolfobolconte\n",
    "\n",
    "Data: 14 de Janeiro de 2020\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Carregar Conjunto de Dados com informações de Diagnósticos de Câncer de Mama para realizar a Classificação (em Malígno ou Benígno) destes dados utilizando algoritmos de Aprendizado de Máquina Supervisionado em Python com alterações do Conjunto de Dados e também parâmetros dos modelos, além de usar métricas estatísticas voltadas para mensuração de Modelos de Classificação de Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0- Carregando Código\n",
    "\n",
    "Cópia de trechos do código já utilizado na Parte 1 (https://github.com/rodolfobolconte/minicurso-aprendizado-supervisionado/blob/master/Parte%201.ipynb) para carregar o Conjunto de Dados e tratá-lo para ser utilizado a partir das Reamostragens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#transforma os numpy arrays em arrays python\n",
    "samples = np.ndarray.tolist(dataset.data)\n",
    "feature_names = np.ndarray.tolist(dataset.feature_names)\n",
    "\n",
    "#insere a coluna 'target' no array de atributos\n",
    "feature_names.append('target')\n",
    "\n",
    "#insere o array de atributos no início do array de amostras\n",
    "samples.insert(0, feature_names)\n",
    "\n",
    "#variavel com os rótulos das amostras\n",
    "targets = np.ndarray.tolist(dataset.target)\n",
    "\n",
    "#coloca o rótulo de cada amostra em seu próprio array no array de amostras\n",
    "for sample, target in zip(samples[1:], targets):\n",
    "    sample.append(target)\n",
    "\n",
    "#transforma o array python com as amostras em um numpy array para ser transformado em dataframe pandas, por ser melhor estruturado\n",
    "samples = np.asarray(samples)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#transforma o numpy array com as amostras em dataframe pandas\n",
    "samples = pd.DataFrame(samples[1:], index=samples[1:], columns=samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Reamostragem de Dados\n",
    "\n",
    "Construção de _Datasets_ a partir de métodos de Reamostragem:\n",
    "- _Holdout_: divisão do _Dataset_ em dois subconjuntos sem Reposição dos Dados;\n",
    "- _Bootstrap_: divisão do _Dataset_ em dois subconjuntos com Reposição dos Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#divide os dados para classificação (X) e os rótulos (Y) dos mesmos\n",
    "X = samples[feature_names[:-1]]\n",
    "Y = samples[feature_names[-1]]\n",
    "\n",
    "#transforma os rótulos em booleanos para ser utilizado no método de dividir o Dataset\n",
    "Y = [True if i == '1' else False for i in Y]\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Holdout, com 60% para treino e 40% para teste\n",
    "trainXHT, testXHT, trainYHT, testYHT = train_test_split(X, Y, train_size=0.66)\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Bootstrap, com 60% para treino e 40% para teste\n",
    "trainXBT, testXBT, trainYBT, testYBT = train_test_split(X, Y, train_size=0.66, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2- Algoritmos de Classificação\n",
    "\n",
    "Construção dos modelos editando suas configurações para criar as melhores combinações possíveis para Classificações com bons resultados.\n",
    "\n",
    "Serão utilizados os modelos:\n",
    "- _Multinomial Naive Bayes_: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html;\n",
    "- _Decision Tree_: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html;\n",
    "- _Random Forest_: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html;\n",
    "- _Adaptive Boosting_: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "#Modelos Multinomial Naive Bayes para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "modelMNHT = MultinomialNB() ; modelMNBT = MultinomialNB()\n",
    "\n",
    "#Modelos Decision Tree para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "modelDTHT = DecisionTreeClassifier() ; modelDTBT = DecisionTreeClassifier()\n",
    "\n",
    "#Modelos Random Forest para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "modelRFHT = RandomForestClassifier() ; modelRFBT = RandomForestClassifier()\n",
    "\n",
    "#Modelos Adaptive Boosting para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "modelABHT = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=) ; modelABBT = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1- Treino e Teste dos Algoritmos\n",
    "\n",
    "Nessa etapa os algoritmos serão treinados e testados com seus respectivos conjuntos de dados para que suas previsões sejam analisadas a partir de métricas estatísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treino dos algoritmos com reamostragem holdout\n",
    "modelMNHT.fit(trainXHT, trainYHT)\n",
    "modelDTHT.fit(trainXHT, trainYHT)\n",
    "modelRFHT.fit(trainXHT, trainYHT)\n",
    "modelABHT.fit(trainXHT, trainYHT)\n",
    "#treino dos algoritmos com reamostragem bootstrap\n",
    "modelMNBT.fit(trainXBT, trainYBT)\n",
    "modelDTBT.fit(trainXBT, trainYBT)\n",
    "modelRFBT.fit(trainXBT, trainYBT)\n",
    "modelABBT.fit(trainXBT, trainYBT)\n",
    "\n",
    "#previsão dos algoritmos com reamostragem holdout\n",
    "previsionMNHT = modelMNHT.predict(testXHT)\n",
    "previsionDTHT = modelDTHT.predict(testXHT)\n",
    "previsionRFHT = modelRFHT.predict(testXHT)\n",
    "previsionABHT = modelABHT.predict(testXHT)\n",
    "#previsão dos algoritmos com reamostragem bootstrap\n",
    "previsionMNBT = modelMNBT.predict(testXBT)\n",
    "previsionDTBT = modelDTBT.predict(testXBT)\n",
    "previsionRFBT = modelRFBT.predict(testXBT)\n",
    "previsionABBT = modelABBT.predict(testXBT)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Resultados\n",
    "\n",
    "Diversas são as formas de comparar os resultados obtidos nas Previsões dos modelos, sendo comum a utilização da Matriz de Confusão que calcula os 4 resultados possíveis:\n",
    "- Verdadeiro Negativo (VN) - `confusion_matrix[0][0]`;\n",
    "- Falso Positivo (FP) - `confusion_matrix[0][1]`;\n",
    "- Falso Negativo (FN) - `confusion_matrix[1][0]`;\n",
    "- Verdadeiro Positivo (VP) - `confusion_matrix[1][1]`.\n",
    "\n",
    "\n",
    "Os 4 resultados podem ser utilizados em diversas métricas estatísticas, das quais serão utilizadas:\n",
    "- Acurácia (_Accuracy_);\n",
    "- Precisão (_Precision_);\n",
    "- Sensibilidade (_Recall_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "#criando dicionários para armazenar métricas de cada modelo e de cada tipo de reamostragem\n",
    "metricsMN = dict() ; metricsMN['holdout'] = dict() ; metricsMN['bootstrap'] = dict()\n",
    "metricsDT = dict() ; metricsDT['holdout'] = dict() ; metricsDT['bootstrap'] = dict()\n",
    "metricsRF = dict() ; metricsRF['holdout'] = dict() ; metricsRF['bootstrap'] = dict()\n",
    "metricsAB = dict() ; metricsAB['holdout'] = dict() ; metricsAB['bootstrap'] = dict()\n",
    "\n",
    "#metricas para Multinomial NB rodando os dados holdout\n",
    "metricsMN['holdout']['confusion'] = confusion_matrix(testYHT, previsionMNHT)\n",
    "metricsMN['holdout']['accuracy'] = accuracy_score(testYHT, previsionMNHT)# * 100\n",
    "metricsMN['holdout']['precision'] = precision_score(testYHT, previsionMNHT)# * 100\n",
    "metricsMN['holdout']['recall'] = recall_score(testYHT, previsionMNHT)# * 100\n",
    "#metricas para Multinomial NB rodando os dados bootstrap\n",
    "metricsMN['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionMNBT)\n",
    "metricsMN['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionMNBT)# * 100\n",
    "metricsMN['bootstrap']['precision'] = precision_score(testYBT, previsionMNBT)# * 100\n",
    "metricsMN['bootstrap']['recall'] = recall_score(testYBT, previsionMNBT)# * 100\n",
    "\n",
    "\n",
    "#metricas para Decision Tree rodando os dados holdout\n",
    "metricsDT['holdout']['confusion'] = confusion_matrix(testYHT, previsionDTHT)\n",
    "metricsDT['holdout']['accuracy'] = accuracy_score(testYHT, previsionDTHT)# * 100\n",
    "metricsDT['holdout']['precision'] = precision_score(testYHT, previsionDTHT)# * 100\n",
    "metricsDT['holdout']['recall'] = recall_score(testYHT, previsionDTHT)# * 100\n",
    "#metricas para Decision Tree rodando os dados bootstrap\n",
    "metricsDT['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionDTBT)\n",
    "metricsDT['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionDTBT)# * 100\n",
    "metricsDT['bootstrap']['precision'] = precision_score(testYBT, previsionDTBT)# * 100\n",
    "metricsDT['bootstrap']['recall'] = recall_score(testYBT, previsionDTBT)# * 100\n",
    "\n",
    "\n",
    "#metricas para Random Forest rodando os dados holdout\n",
    "metricsRF['holdout']['confusion'] = confusion_matrix(testYHT, previsionRFHT)\n",
    "metricsRF['holdout']['accuracy'] = accuracy_score(testYHT, previsionRFHT)# * 100\n",
    "metricsRF['holdout']['precision'] = precision_score(testYHT, previsionRFHT)# * 100\n",
    "metricsRF['holdout']['recall'] = recall_score(testYHT, previsionRFHT)# * 100\n",
    "#metricas para Random Forest rodando os dados bootstrap\n",
    "metricsRF['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionRFBT)\n",
    "metricsRF['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionRFBT)# * 100\n",
    "metricsRF['bootstrap']['precision'] = precision_score(testYBT, previsionRFBT)# * 100\n",
    "metricsRF['bootstrap']['recall'] = recall_score(testYBT, previsionRFBT)# * 100\n",
    "\n",
    "\n",
    "#metricas para Adaptive Boosting rodando os dados holdout\n",
    "metricsAB['holdout']['confusion'] = confusion_matrix(testYHT, previsionABHT)\n",
    "metricsAB['holdout']['accuracy'] = accuracy_score(testYHT, previsionABHT)# * 100\n",
    "metricsAB['holdout']['precision'] = precision_score(testYHT, previsionABHT)# * 100\n",
    "metricsAB['holdout']['recall'] = recall_score(testYHT, previsionABHT)# * 100\n",
    "#metricas para Adaptive Boosting rodando os dados bootstrap\n",
    "metricsAB['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionABBT)\n",
    "metricsAB['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionABBT)# * 100\n",
    "metricsAB['bootstrap']['precision'] = precision_score(testYBT, previsionABBT)# * 100\n",
    "metricsAB['bootstrap']['recall'] = recall_score(testYBT, previsionABBT)# * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1- Exportando Resultados\n",
    "\n",
    "Exportar todos os resultados para arquivo .CSV de melhor interpretação e apresentação de valores utilizando um editor de Planilhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = open('Parte 2 - Resultados.csv', 'w')\n",
    "\n",
    "csv.write('Algoritmos;Métricas Bootstrap;;;;;Métricas Holdout')\n",
    "csv.write('\\n;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade;')\n",
    "\n",
    "csv.write(\"\\nMultinomial NB;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsMN['holdout']['confusion'][0], metricsMN['holdout']['confusion'][1], metricsMN['holdout']['accuracy'], metricsMN['holdout']['precision'], metricsMN['holdout']['recall'], metricsMN['holdout']['confusion'][0], metricsMN['holdout']['confusion'][1], metricsMN['bootstrap']['accuracy'], metricsMN['bootstrap']['precision'], metricsMN['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nDecision Tree;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsDT['holdout']['confusion'][0], metricsDT['holdout']['confusion'][1], metricsDT['holdout']['accuracy'], metricsDT['holdout']['precision'], metricsDT['holdout']['recall'], metricsDT['holdout']['confusion'][0], metricsDT['holdout']['confusion'][1], metricsDT['bootstrap']['accuracy'], metricsDT['bootstrap']['precision'], metricsDT['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nRandom Forest;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsRF['holdout']['confusion'][0], metricsRF['holdout']['confusion'][1], metricsRF['holdout']['accuracy'], metricsRF['holdout']['precision'], metricsRF['holdout']['recall'], metricsRF['holdout']['confusion'][0], metricsRF['holdout']['confusion'][1], metricsRF['bootstrap']['accuracy'], metricsRF['bootstrap']['precision'], metricsRF['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nAdaptive Boosting;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsAB['holdout']['confusion'][0], metricsAB['holdout']['confusion'][1], metricsAB['holdout']['accuracy'], metricsAB['holdout']['precision'], metricsAB['holdout']['recall'], metricsAB['holdout']['confusion'][0], metricsAB['holdout']['confusion'][1], metricsAB['bootstrap']['accuracy'], metricsAB['bootstrap']['precision'], metricsAB['bootstrap']['recall']))"
   ]
  }
 ]
}