{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitcefaae51de97494c8b3e896cae0342ea",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dados com Python 3\n",
    "\n",
    "## 0- Objetivo\n",
    "\n",
    "Carregar Conjunto de Dados com informações de Diagnósticos de Câncer de Mama para realizar a Classificação (em Malígno ou Benígno) destes dados utilizando algoritmos de Aprendizado de Máquina Supervisionado em Python.\n",
    "\n",
    "## 1- Conjunto de Dados (_Dataset_)\n",
    "\n",
    "Conjunto com amostras de Diagnósticos de Câncer de Mama com duas Classificações: Malígno (M) e Benígno (B).\n",
    "\n",
    "Informações do Conjunto:\n",
    "- Construído em 1995;\n",
    "- Origem: `scikit-learn`;\n",
    "- Estrutura de Dados ao Carregar: `bunch`;\n",
    "- Atributos da Estrutura:\n",
    "    - `target`: rótulos das amostras;\n",
    "    - `target_names`: significado dos rótulos;\n",
    "    - `feature`names`: nome dos atributos;\n",
    "    - `DESCR`: descrição do Conjunto de Dados;\n",
    "    - `filename`: localização do Conjunto de Dados em .CSV.\n",
    "- Página do Conjunto de Dados: http://bit.ly/load_breast_cancer\n",
    "\n",
    "Informações dos Dados:\n",
    "- Número de Diagnósticos (Amostras): 569;\n",
    "- Duas Classificações:\n",
    "    - Diagnósticos Malígnos: 212;\n",
    "    - Diagnósticos Benígnos: 357.\n",
    "- Quantidade de Atributos: 30.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Resultados\n",
    "\n",
    "Diversas são as formas de comparar os resultados obtidos nas Previsões dos modelos, sendo comum a utilização da Matriz de Confusão que calcula os 4 resultados possíveis:\n",
    "- Verdadeiro Negativo (VN) - `confusion_matrix[0][0]`;\n",
    "- Falso Positivo (FP) - `confusion_matrix[0][1]`;\n",
    "- Falso Negativo (FN) - `confusion_matrix[1][0]`;\n",
    "- Verdadeiro Positivo (VP) - `confusion_matrix[1][1]`.\n",
    "\n",
    "\n",
    "Os 4 resultados podem ser utilizados em diversas métricas estatísticas, das quais serão utilizadas:\n",
    "- Acurácia (_Accuracy_);\n",
    "- Precisão (_Precision_);\n",
    "- Sensibilidade (_Recall_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "#criando dicionários para armazenar métricas de cada modelo\n",
    "metricsMNB = {} ; metricsDT = {} ; metricsRF = {} ; metricsAB = {}\n",
    "\n",
    "#armazenando as métricas para cada modelo\n",
    "metricsMNB['confusion'] = confusion_matrix(testY, previsionMNB)\n",
    "metricsMNB['accuracy'] = accuracy_score(testY, previsionMNB)\n",
    "metricsMNB['precision'] = precision_score(testY, previsionMNB)\n",
    "metricsMNB['recall'] = recall_score(testY, previsionMNB)\n",
    "\n",
    "metricsDT['confusion'] = confusion_matrix(testY, previsionDT)\n",
    "metricsDT['accuracy'] = accuracy_score(testY, previsionDT)\n",
    "metricsDT['precision'] = precision_score(testY, previsionDT)\n",
    "metricsDT['recall'] = recall_score(testY, previsionDT)\n",
    "\n",
    "metricsRF['confusion'] = confusion_matrix(testY, previsionRF)\n",
    "metricsRF['accuracy'] = accuracy_score(testY, previsionRF)\n",
    "metricsRF['precision'] = precision_score(testY, previsionRF)\n",
    "metricsRF['recall'] = recall_score(testY, previsionRF)\n",
    "\n",
    "metricsAB['confusion'] = confusion_matrix(testY, previsionAB)\n",
    "metricsAB['accuracy'] = accuracy_score(testY, previsionAB)\n",
    "metricsAB['precision'] = precision_score(testY, previsionAB)\n",
    "metricsAB['recall'] = recall_score(testY, previsionAB)\n",
    "\n",
    "\n",
    "print('Resultados Métricos:')\n",
    "\n",
    "print('\\nMultinomial Naive Bayes:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsMNB['confusion'][0][0], metricsMNB['confusion'][0][1], metricsMNB['confusion'][1][0], metricsMNB['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsMNB['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsMNB['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsMNB['recall']))\n",
    "\n",
    "print('\\nDecision Tree:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsDT['confusion'][0][0], metricsDT['confusion'][0][1], metricsDT['confusion'][1][0], metricsDT['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsDT['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsDT['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsDT['recall']))\n",
    "\n",
    "print('\\nFloresta Aleatória:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsRF['confusion'][0][0], metricsRF['confusion'][0][1], metricsRF['confusion'][1][0], metricsRF['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsRF['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsRF['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsRF['recall']))\n",
    "\n",
    "print('\\nAumento Adaptativo:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsAB['confusion'][0][0], metricsAB['confusion'][0][1], metricsAB['confusion'][1][0], metricsAB['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsAB['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsAB['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsAB['recall']))"
   ]
  }
 ]
}