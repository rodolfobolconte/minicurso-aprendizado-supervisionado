{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dados com Python 3 - Parte 2\n",
    "\n",
    "Autor: Rodolfo Bolconte Donato - https://github.com/rodolfobolconte\n",
    "\n",
    "Data: 12 de Fevereiro de 2020\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Carregar Conjunto de Dados com informações de Diagnósticos de Câncer de Mama;\n",
    "- Reamostrar o Conjunto de Dados utilizando os método _Holdout_ e _Bootstrap_;\n",
    "- Carregar Algoritmos de Aprendizado de Máquina Supervisionado para a Classificão dos Dados (entre Benígno e Malígno);\n",
    "- Comparar combinações de parâmetros dos Algoritmos de Classificação;\n",
    "- Utilizar Métricas Estatísticas voltadas para a mensuração de Modelos de Classificação de Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0- Carregando Código\n",
    "\n",
    "Cópia de trechos do código já utilizado na [Parte 1](https://github.com/rodolfobolconte/minicurso-aprendizado-supervisionado/blob/master/Parte%201.ipynb) para carregar o Conjunto de Dados e tratá-lo para ser utilizado a partir das Reamostragens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#transforma os numpy arrays em arrays python\n",
    "samples = np.ndarray.tolist(dataset.data)\n",
    "feature_names = np.ndarray.tolist(dataset.feature_names)\n",
    "\n",
    "#insere a coluna 'target' no array de atributos\n",
    "feature_names.append('target')\n",
    "\n",
    "#insere o array de atributos no início do array de amostras\n",
    "samples.insert(0, feature_names)\n",
    "\n",
    "#variavel com os rótulos das amostras\n",
    "targets = np.ndarray.tolist(dataset.target)\n",
    "\n",
    "#coloca o rótulo de cada amostra em seu próprio array no array de amostras\n",
    "for sample, target in zip(samples[1:], targets):\n",
    "    sample.append(target)\n",
    "\n",
    "#transforma o array python com as amostras em um numpy array para ser transformado em dataframe pandas, por ser melhor estruturado\n",
    "samples = np.asarray(samples)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#transforma o numpy array com as amostras em dataframe pandas\n",
    "samples = pd.DataFrame(samples[1:], index=samples[1:], columns=samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Reamostragem de Dados\n",
    "\n",
    "Construção de _Datasets_ a partir de métodos de Reamostragem:\n",
    "- _Holdout_: divisão do _Dataset_ em dois subconjuntos sem Reposição dos Dados;\n",
    "- _Bootstrap_: divisão do _Dataset_ em dois subconjuntos com Reposição dos Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#divide os dados para classificação (X) e os rótulos (Y) dos mesmos\n",
    "X = samples[feature_names[:-1]]\n",
    "Y = samples[feature_names[-1]]\n",
    "\n",
    "#transforma os rótulos em booleanos para ser utilizado no método de dividir o Dataset\n",
    "Y = [True if i == '1' else False for i in Y]\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Holdout, com 60% para treino e 40% para teste\n",
    "trainXHT, testXHT, trainYHT, testYHT = train_test_split(X, Y, train_size=0.66)\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Bootstrap, com 60% para treino e 40% para teste\n",
    "trainXBT, testXBT, trainYBT, testYBT = train_test_split(X, Y, train_size=0.66, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2- Algoritmos de Classificação\n",
    "\n",
    "Construção dos modelos editando suas configurações para criar as melhores combinações possíveis para Classificações com bons resultados.\n",
    "\n",
    "Serão utilizados os modelos:\n",
    "- [_Multinomial Naive Bayes_](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html);\n",
    "- [_Decision Tree_](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html);\n",
    "- [_Random Forest_](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html);\n",
    "- [_Adaptive Boosting_](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "#Modelos Multinomial Naive Bayes para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "alpha = 0.5\n",
    "fit_prior = False\n",
    "class_prior = [0.25, 0.5]\n",
    "modelMNHT = MultinomialNB(alpha=alpha,\n",
    "                          fit_prior=fit_prior,\n",
    "                          class_prior=class_prior)\n",
    "modelMNBT = MultinomialNB(alpha=alpha,\n",
    "                          fit_prior=fit_prior,\n",
    "                          class_prior=class_prior)\n",
    "\n",
    "#Modelos Decision Tree para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "criterion = 'entropy' #'gini' ou 'entropy'\n",
    "splitter = 'random' #'best' ou 'random'\n",
    "max_depth = 4\n",
    "min_samples_split = 4\n",
    "min_samples_leaf = 2\n",
    "max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None\n",
    "max_leaf_nodes = 8\n",
    "modelDTHT = DecisionTreeClassifier(criterion=criterion,\n",
    "                                   splitter=splitter,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes)\n",
    "modelDTBT = DecisionTreeClassifier(criterion=criterion,\n",
    "                                   splitter=splitter,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "#Modelos Random Forest para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "n_estimators = 50\n",
    "criterion = 'entropy' #'gini' ou 'entropy'\n",
    "max_depth = 4\n",
    "min_samples_split = 4\n",
    "min_samples_leaf = 2\n",
    "max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None\n",
    "max_leaf_nodes = 8\n",
    "bootstrap = False\n",
    "max_samples = 0.5 #intervalo entre 0 e 1\n",
    "modelRFHT = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                   bootstrap=bootstrap,\n",
    "                                   max_samples=max_samples)\n",
    "modelRFBT = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                   bootstrap=bootstrap,\n",
    "                                   max_samples=max_samples)\n",
    "\n",
    "#Modelos Adaptive Boosting para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "base_estimator = None\n",
    "n_estimators = 100\n",
    "learning_rate = 2\n",
    "algorithm = 'SAMME' # 'SAMME.R' ou 'SAMME'\n",
    "modelABHT = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                               n_estimators=n_estimators,\n",
    "                               learning_rate=learning_rate,\n",
    "                               algorithm=algorithm)\n",
    "modelABBT = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                               n_estimators=n_estimators,\n",
    "                               learning_rate=learning_rate,\n",
    "                               algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1- Treino e Teste dos Algoritmos\n",
    "\n",
    "Nessa etapa os algoritmos serão treinados e testados com seus respectivos conjuntos de dados para que suas previsões sejam analisadas a partir de métricas estatísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treino dos algoritmos com reamostragem holdout\n",
    "modelMNHT.fit(trainXHT, trainYHT)\n",
    "modelDTHT.fit(trainXHT, trainYHT)\n",
    "modelRFHT.fit(trainXHT, trainYHT)\n",
    "modelABHT.fit(trainXHT, trainYHT)\n",
    "#treino dos algoritmos com reamostragem bootstrap\n",
    "modelMNBT.fit(trainXBT, trainYBT)\n",
    "modelDTBT.fit(trainXBT, trainYBT)\n",
    "modelRFBT.fit(trainXBT, trainYBT)\n",
    "modelABBT.fit(trainXBT, trainYBT)\n",
    "\n",
    "#previsão dos algoritmos com reamostragem holdout\n",
    "previsionMNHT = modelMNHT.predict(testXHT)\n",
    "previsionDTHT = modelDTHT.predict(testXHT)\n",
    "previsionRFHT = modelRFHT.predict(testXHT)\n",
    "previsionABHT = modelABHT.predict(testXHT)\n",
    "#previsão dos algoritmos com reamostragem bootstrap\n",
    "previsionMNBT = modelMNBT.predict(testXBT)\n",
    "previsionDTBT = modelDTBT.predict(testXBT)\n",
    "previsionRFBT = modelRFBT.predict(testXBT)\n",
    "previsionABBT = modelABBT.predict(testXBT)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Resultados\n",
    "\n",
    "Diversas são as formas de comparar os resultados obtidos nas Previsões dos modelos, sendo comum a utilização da Matriz de Confusão que calcula os 4 resultados possíveis:\n",
    "- Verdadeiro Negativo (VN) - `confusion_matrix[0][0]`;\n",
    "- Falso Positivo (FP) - `confusion_matrix[0][1]`;\n",
    "- Falso Negativo (FN) - `confusion_matrix[1][0]`;\n",
    "- Verdadeiro Positivo (VP) - `confusion_matrix[1][1]`.\n",
    "\n",
    "\n",
    "Os 4 resultados podem ser utilizados em diversas métricas estatísticas, das quais serão utilizadas:\n",
    "- Acurácia (_Accuracy_);\n",
    "- Precisão (_Precision_);\n",
    "- Sensibilidade (_Recall_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "#criando dicionários para armazenar métricas de cada modelo e de cada tipo de reamostragem\n",
    "metricsMN = dict() ; metricsMN['holdout'] = dict() ; metricsMN['bootstrap'] = dict()\n",
    "metricsDT = dict() ; metricsDT['holdout'] = dict() ; metricsDT['bootstrap'] = dict()\n",
    "metricsRF = dict() ; metricsRF['holdout'] = dict() ; metricsRF['bootstrap'] = dict()\n",
    "metricsAB = dict() ; metricsAB['holdout'] = dict() ; metricsAB['bootstrap'] = dict()\n",
    "\n",
    "#metricas para Multinomial NB rodando os dados holdout\n",
    "metricsMN['holdout']['confusion'] = confusion_matrix(testYHT, previsionMNHT)\n",
    "metricsMN['holdout']['accuracy'] = accuracy_score(testYHT, previsionMNHT)\n",
    "metricsMN['holdout']['precision'] = precision_score(testYHT, previsionMNHT)\n",
    "metricsMN['holdout']['recall'] = recall_score(testYHT, previsionMNHT)\n",
    "#metricas para Multinomial NB rodando os dados bootstrap\n",
    "metricsMN['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionMNBT)\n",
    "metricsMN['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionMNBT)\n",
    "metricsMN['bootstrap']['precision'] = precision_score(testYBT, previsionMNBT)\n",
    "metricsMN['bootstrap']['recall'] = recall_score(testYBT, previsionMNBT)\n",
    "\n",
    "\n",
    "#metricas para Decision Tree rodando os dados holdout\n",
    "metricsDT['holdout']['confusion'] = confusion_matrix(testYHT, previsionDTHT)\n",
    "metricsDT['holdout']['accuracy'] = accuracy_score(testYHT, previsionDTHT)\n",
    "metricsDT['holdout']['precision'] = precision_score(testYHT, previsionDTHT)\n",
    "metricsDT['holdout']['recall'] = recall_score(testYHT, previsionDTHT)\n",
    "#metricas para Decision Tree rodando os dados bootstrap\n",
    "metricsDT['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionDTBT)\n",
    "metricsDT['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionDTBT)\n",
    "metricsDT['bootstrap']['precision'] = precision_score(testYBT, previsionDTBT)\n",
    "metricsDT['bootstrap']['recall'] = recall_score(testYBT, previsionDTBT)\n",
    "\n",
    "\n",
    "#metricas para Random Forest rodando os dados holdout\n",
    "metricsRF['holdout']['confusion'] = confusion_matrix(testYHT, previsionRFHT)\n",
    "metricsRF['holdout']['accuracy'] = accuracy_score(testYHT, previsionRFHT)\n",
    "metricsRF['holdout']['precision'] = precision_score(testYHT, previsionRFHT)\n",
    "metricsRF['holdout']['recall'] = recall_score(testYHT, previsionRFHT)\n",
    "#metricas para Random Forest rodando os dados bootstrap\n",
    "metricsRF['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionRFBT)\n",
    "metricsRF['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionRFBT)\n",
    "metricsRF['bootstrap']['precision'] = precision_score(testYBT, previsionRFBT)\n",
    "metricsRF['bootstrap']['recall'] = recall_score(testYBT, previsionRFBT)\n",
    "\n",
    "\n",
    "#metricas para Adaptive Boosting rodando os dados holdout\n",
    "metricsAB['holdout']['confusion'] = confusion_matrix(testYHT, previsionABHT)\n",
    "metricsAB['holdout']['accuracy'] = accuracy_score(testYHT, previsionABHT)\n",
    "metricsAB['holdout']['precision'] = precision_score(testYHT, previsionABHT)\n",
    "metricsAB['holdout']['recall'] = recall_score(testYHT, previsionABHT)\n",
    "#metricas para Adaptive Boosting rodando os dados bootstrap\n",
    "metricsAB['bootstrap']['confusion'] = confusion_matrix(testYBT, previsionABBT)\n",
    "metricsAB['bootstrap']['accuracy'] = accuracy_score(testYBT, previsionABBT)\n",
    "metricsAB['bootstrap']['precision'] = precision_score(testYBT, previsionABBT)\n",
    "metricsAB['bootstrap']['recall'] = recall_score(testYBT, previsionABBT)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1- Exportando Resultados\n",
    "\n",
    "Exportar todos os resultados para arquivo .CSV de melhor interpretação e apresentação de valores utilizando um editor de Planilhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "94"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = open('Parte 2 - Resultados.csv', 'w')\n",
    "\n",
    "csv.write('RodolfoAlgoritmos;Métricas Bootstrap;;;;;Métricas Holdout')\n",
    "csv.write('\\n;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade;')\n",
    "\n",
    "csv.write(\"\\nMultinomial NB;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsMN['holdout']['confusion'][0], metricsMN['holdout']['confusion'][1], metricsMN['holdout']['accuracy'], metricsMN['holdout']['precision'], metricsMN['holdout']['recall'], metricsMN['bootstrap']['confusion'][0], metricsMN['bootstrap']['confusion'][1], metricsMN['bootstrap']['accuracy'], metricsMN['bootstrap']['precision'], metricsMN['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nDecision Tree;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsDT['holdout']['confusion'][0], metricsDT['holdout']['confusion'][1], metricsDT['holdout']['accuracy'], metricsDT['holdout']['precision'], metricsDT['holdout']['recall'], metricsDT['bootstrap']['confusion'][0], metricsDT['bootstrap']['confusion'][1], metricsDT['bootstrap']['accuracy'], metricsDT['bootstrap']['precision'], metricsDT['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nRandom Forest;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsRF['holdout']['confusion'][0], metricsRF['holdout']['confusion'][1], metricsRF['holdout']['accuracy'], metricsRF['holdout']['precision'], metricsRF['holdout']['recall'], metricsRF['bootstrap']['confusion'][0], metricsRF['bootstrap']['confusion'][1], metricsRF['bootstrap']['accuracy'], metricsRF['bootstrap']['precision'], metricsRF['bootstrap']['recall']))\n",
    "\n",
    "csv.write(\"\\nAdaptive Boosting;%s;%s;%.4f;%.4f;%.4f;%s;%s;%.4f;%.4f;%.4f\" %(metricsAB['holdout']['confusion'][0], metricsAB['holdout']['confusion'][1], metricsAB['holdout']['accuracy'], metricsAB['holdout']['precision'], metricsAB['holdout']['recall'], metricsAB['bootstrap']['confusion'][0], metricsAB['bootstrap']['confusion'][1], metricsAB['bootstrap']['accuracy'], metricsAB['bootstrap']['precision'], metricsAB['bootstrap']['recall']))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitcefaae51de97494c8b3e896cae0342ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}