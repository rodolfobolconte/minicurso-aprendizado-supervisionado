{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitcefaae51de97494c8b3e896cae0342ea",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dados com Python 3 - Parte 2\n",
    "\n",
    "Autor: Rodolfo Bolconte Donato - https://github.com/rodolfobolconte\n",
    "\n",
    "Data: 14 de Janeiro de 2020\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Carregar Conjunto de Dados com informações de Diagnósticos de Câncer de Mama para realizar a Classificação (em Malígno ou Benígno) destes dados utilizando algoritmos de Aprendizado de Máquina Supervisionado em Python com alterações do Conjunto de Dados e também parâmetros dos modelos, além de usar métricas estatísticas voltadas para mensuração de Modelos de Classificação de Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0- Carregando Código\n",
    "\n",
    "Cópia de trechos do código já utilizado na Parte 1 (https://github.com/rodolfobolconte/minicurso-aprendizado-supervisionado/blob/master/Parte%201.ipynb) para carregar o Conjunto de Dados e tratá-lo para ser utilizado a partir das Reamostragens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#transforma os numpy arrays em arrays python\n",
    "samples = np.ndarray.tolist(dataset.data)\n",
    "feature_names = np.ndarray.tolist(dataset.feature_names)\n",
    "\n",
    "#insere a coluna 'target' no array de atributos\n",
    "feature_names.append('target')\n",
    "\n",
    "#insere o array de atributos no início do array de amostras\n",
    "samples.insert(0, feature_names)\n",
    "\n",
    "#variavel com os rótulos das amostras\n",
    "targets = np.ndarray.tolist(dataset.target)\n",
    "\n",
    "#coloca o rótulo de cada amostra em seu próprio array no array de amostras\n",
    "for sample, target in zip(samples[1:], targets):\n",
    "    sample.append(target)\n",
    "\n",
    "#transforma o array python com as amostras em um numpy array para ser transformado em dataframe pandas, por ser melhor estruturado\n",
    "samples = np.asarray(samples)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#transforma o numpy array com as amostras em dataframe pandas\n",
    "samples = pd.DataFrame(samples[1:], index=samples[1:], columns=samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Tratamento dos Dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2- Reamostragem de Dados\n",
    "\n",
    "Construção de _Datasets_ a partir de métodos de Reamostragem:\n",
    "- _Holdout_: divisão do _Dataset_ em dois subconjuntos sem Reposição dos Dados;\n",
    "- _K-Fold_: divisão do conjunto em k subconjuntos que serão utilizados para treino e teste simultaneamente k vezes;\n",
    "- _Bootstrap_: divisão do _Dataset_ em dois subconjuntos com Reposição dos Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#divide os dados para classificação (X) e os rótulos (Y) dos mesmos\n",
    "X = samples[feature_names[:-1]]\n",
    "Y = samples[feature_names[-1]]\n",
    "\n",
    "#transforma os rótulos em booleanos para ser utilizado no método de dividir o Dataset\n",
    "Y = [True if i == '1' else False for i in Y]\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Holdout, com 60% para treino e 40% para teste\n",
    "trainXHT, testXHT, trainYHT, testYHT = train_test_split(X, Y, train_size=0.66)\n",
    "\n",
    "#reamostragem K-Fold será realizada na execução do treino e teste dos modelos\n",
    "#divisão do Dataset utilizando a reamostragem K-Fold, com k=10\n",
    "#kf = KFold(n_splits=10)\n",
    "#for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "    #print(X.iloc[train_index])\n",
    "\n",
    "#divisão do Dataset utilizando a reamostragem Bootstrap, com 60% para treino e 40% para teste\n",
    "trainXBT, testXBT, trainYBT, testYBT = train_test_split(X, Y, train_size=0.66, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Algoritmos de Classificação\n",
    "\n",
    "Construção dos modelos editando suas configurações para criar as melhores combinações possíveis para Classificações com bons resultados.\n",
    "\n",
    "Serão utilizados os modelos:\n",
    "- _Multinomial Naive Bayes_: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html;\n",
    "- _Decision Tree_: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html;\n",
    "- _Random Forest_: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html;\n",
    "- _Adaptive Boosting_: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "#MultinomialNB: 3 parâmetros - 8 \n",
    "#fit_prior: se deve aprender com as probabilidades das classes anteriores\n",
    "modelMNB = MultinomialNB()\n",
    "#\n",
    "modelDT = DecisionTreeClassifier()\n",
    "\n",
    "#criando os modelos ensemble methods de classificação\n",
    "modelRF = RandomForestClassifier()\n",
    "modelAB = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Resultados\n",
    "\n",
    "Diversas são as formas de comparar os resultados obtidos nas Previsões dos modelos, sendo comum a utilização da Matriz de Confusão que calcula os 4 resultados possíveis:\n",
    "- Verdadeiro Negativo (VN) - `confusion_matrix[0][0]`;\n",
    "- Falso Positivo (FP) - `confusion_matrix[0][1]`;\n",
    "- Falso Negativo (FN) - `confusion_matrix[1][0]`;\n",
    "- Verdadeiro Positivo (VP) - `confusion_matrix[1][1]`.\n",
    "\n",
    "\n",
    "Os 4 resultados podem ser utilizados em diversas métricas estatísticas, das quais serão utilizadas:\n",
    "- Acurácia (_Accuracy_);\n",
    "- Precisão (_Precision_);\n",
    "- Sensibilidade (_Recall_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'previsionMNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-f9d2239fb6fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#armazenando as métricas para cada modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmetricsMNB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'confusion'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevisionMNB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmetricsMNB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevisionMNB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmetricsMNB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevisionMNB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'previsionMNB' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "#criando dicionários para armazenar métricas de cada modelo\n",
    "metricsMNB = {} ; metricsDT = {} ; metricsRF = {} ; metricsAB = {}\n",
    "\n",
    "#armazenando as métricas para cada modelo\n",
    "metricsMNB['confusion'] = confusion_matrix(testY, previsionMNB)\n",
    "metricsMNB['accuracy'] = accuracy_score(testY, previsionMNB)\n",
    "metricsMNB['precision'] = precision_score(testY, previsionMNB)\n",
    "metricsMNB['recall'] = recall_score(testY, previsionMNB)\n",
    "\n",
    "metricsDT['confusion'] = confusion_matrix(testY, previsionDT)\n",
    "metricsDT['accuracy'] = accuracy_score(testY, previsionDT)\n",
    "metricsDT['precision'] = precision_score(testY, previsionDT)\n",
    "metricsDT['recall'] = recall_score(testY, previsionDT)\n",
    "\n",
    "metricsRF['confusion'] = confusion_matrix(testY, previsionRF)\n",
    "metricsRF['accuracy'] = accuracy_score(testY, previsionRF)\n",
    "metricsRF['precision'] = precision_score(testY, previsionRF)\n",
    "metricsRF['recall'] = recall_score(testY, previsionRF)\n",
    "\n",
    "metricsAB['confusion'] = confusion_matrix(testY, previsionAB)\n",
    "metricsAB['accuracy'] = accuracy_score(testY, previsionAB)\n",
    "metricsAB['precision'] = precision_score(testY, previsionAB)\n",
    "metricsAB['recall'] = recall_score(testY, previsionAB)\n",
    "\n",
    "\n",
    "print('Resultados Métricos:')\n",
    "\n",
    "print('\\nMultinomial Naive Bayes:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsMNB['confusion'][0][0], metricsMNB['confusion'][0][1], metricsMNB['confusion'][1][0], metricsMNB['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsMNB['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsMNB['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsMNB['recall']))\n",
    "\n",
    "print('\\nDecision Tree:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsDT['confusion'][0][0], metricsDT['confusion'][0][1], metricsDT['confusion'][1][0], metricsDT['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsDT['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsDT['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsDT['recall']))\n",
    "\n",
    "print('\\nFloresta Aleatória:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsRF['confusion'][0][0], metricsRF['confusion'][0][1], metricsRF['confusion'][1][0], metricsRF['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsRF['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsRF['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsRF['recall']))\n",
    "\n",
    "print('\\nAumento Adaptativo:')\n",
    "print('\\tMatriz de Confusão - VN:{}, FP:{}, FN:{}, VP:{}'.format(metricsAB['confusion'][0][0], metricsAB['confusion'][0][1], metricsAB['confusion'][1][0], metricsAB['confusion'][1][1]))\n",
    "print('\\tAcurácia - {:.4f}'.format(metricsAB['accuracy']))\n",
    "print('\\tPrecisão - {:.4f}'.format(metricsAB['precision']))\n",
    "print('\\tSensibilidade - {:.4f}'.format(metricsAB['recall']))"
   ]
  }
 ]
}