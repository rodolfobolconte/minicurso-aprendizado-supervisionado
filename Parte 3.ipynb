{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitcefaae51de97494c8b3e896cae0342ea",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dados com Python 3 - Parte 3\n",
    "\n",
    "Autor: Rodolfo Bolconte Donato - https://github.com/rodolfobolconte\n",
    "\n",
    "Data: 13 de Fevereiro de 2020\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Carregar Conjunto de Dados com informações de Diagnósticos de Câncer de Mama;\n",
    "- Reamostragem do Conjunto de Dados utilizando o método _K-Fold_;\n",
    "- Carregar Algoritmos de Aprendizado de Máquina Supervisionado para a Classificão dos Dados (entre Benígno e Malígno);\n",
    "- Utilizar as melhores combinações de parâmetros dos Algoritmos encontradas;\n",
    "- Utilizar Métricas Estatísticas voltadas para a mensuração de Modelos de Classificação de Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0- Carregando Código\n",
    "\n",
    "Cópia de trechos do código já utilizado na [Parte 2](https://github.com/rodolfobolconte/minicurso-aprendizado-supervisionado/blob/master/Parte%202.ipynb) para carregar os Algoritmos de Aprendizado de Máquina com as melhores combinações de parâmetros encontradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "#Modelos Multinomial Naive Bayes para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "alpha = 0.5\n",
    "fit_prior = False\n",
    "class_prior = [0.25, 0.5]\n",
    "modelMN = MultinomialNB(alpha=alpha,\n",
    "                          fit_prior=fit_prior,\n",
    "                          class_prior=class_prior)\n",
    "\n",
    "#Modelos Decision Tree para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "criterion = 'entropy' #'gini' ou 'entropy'\n",
    "splitter = 'random' #'best' ou 'random'\n",
    "max_depth = 4\n",
    "min_samples_split = 4\n",
    "min_samples_leaf = 2\n",
    "max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None\n",
    "max_leaf_nodes = 8\n",
    "modelDT = DecisionTreeClassifier(criterion=criterion,\n",
    "                                   splitter=splitter,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "#Modelos Random Forest para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "n_estimators = 50\n",
    "criterion = 'entropy' #'gini' ou 'entropy'\n",
    "max_depth = 4\n",
    "min_samples_split = 4\n",
    "min_samples_leaf = 2\n",
    "max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None\n",
    "max_leaf_nodes = 8\n",
    "bootstrap = False\n",
    "max_samples = 0.5 #intervalo entre 0 e 1\n",
    "modelRF = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features,\n",
    "                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                   bootstrap=bootstrap,\n",
    "                                   max_samples=max_samples)\n",
    "\n",
    "#Modelos Adaptive Boosting para serem utilizandos com Reamostragem Holdout e Bootstrap\n",
    "base_estimator = None\n",
    "n_estimators = 100\n",
    "learning_rate = 2\n",
    "algorithm = 'SAMME' # 'SAMME.R' ou 'SAMME'\n",
    "modelAB = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                               n_estimators=n_estimators,\n",
    "                               learning_rate=learning_rate,\n",
    "                               algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Conjunto de Dados\n",
    "\n",
    "Carregando o Conjunto de Dados e atribuindo as amostras e seus rótulos para duas variáveis a serem utilizadas na Reamostragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#Carregando o Conjunto de Dados\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "#Colocando os dados em X e os rótulos em Y\n",
    "X = dataset.data\n",
    "Y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2- Reamostragem e Execução\n",
    "\n",
    "Reamostragem do Conjunto de Dados utilizando o método _K-Fold_ onde _k_ subconjuntos são gerados _k_ vezes, em que _k_-1 subconjuntos são utilizados para Treino dos Algoritmos e o subconjunto restante é utilizado para Teste a cada execução _k_.\n",
    "\n",
    "Ao mesmo tempo em que a Reamostragem é feita ao passo de _k_, os algoritmos são Treinados e Testados, visto que guardar os dados a cada iteração _k_ para depois os algoritmos trabalharem com os subconjuntos não é um processo ágil.\n",
    "\n",
    "Além da execução dos Algoritmos, os seus resultados métricos serão armazenados em suas respectivas variáveis, pelo mesmo motivo da execução dos algoritmos ao passo de cada divisão dos subconjuntos do _K-Fold_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "#Quantidade k de subconjuntos e execuções\n",
    "nK = 5\n",
    "#Cria o objeto responsável pela divisão do Conjunto\n",
    "KF = KFold(n_splits=nK)\n",
    "\n",
    "#Criando e Iniciando as variáveis para armazenar os resultados, que serão incrementados\n",
    "metricsMN = dict() ; metricsDT = dict() ; metricsRF = dict() ; metricsAB = dict()\n",
    "metricsMN['confusion'] = 0 ; metricsMN['accuracy'] = 0 ; metricsMN['precision'] = 0 ; metricsMN['recall'] = 0\n",
    "metricsDT['confusion'] = 0 ; metricsDT['accuracy'] = 0 ; metricsDT['precision'] = 0 ; metricsDT['recall'] = 0\n",
    "metricsRF['confusion'] = 0 ; metricsRF['accuracy'] = 0 ; metricsRF['precision'] = 0 ; metricsRF['recall'] = 0\n",
    "metricsAB['confusion'] = 0 ; metricsAB['accuracy'] = 0 ; metricsAB['precision'] = 0 ; metricsAB['recall'] = 0\n",
    "\n",
    "#No escopo do for a função split retorna os indices da divisão dos subconjuntos para as variáveis de treino e teste\n",
    "for trainIndex, testIndex in KF.split(Y):\n",
    "    #Atribui as amostras e seus rótulos para treino e teste no passo k \n",
    "    trainX, testX = X[trainIndex], X[testIndex]\n",
    "    trainY, testY = Y[trainIndex], Y[testIndex]\n",
    "\n",
    "    #Treino dos algoritmos utilizando as amostras de treino\n",
    "    modelMN.fit(trainX, trainY)\n",
    "    modelDT.fit(trainX, trainY)\n",
    "    modelRF.fit(trainX, trainY)\n",
    "    modelAB.fit(trainX, trainY)\n",
    "    \n",
    "    #Previsão dos algoritmos utilizando os dados de teste\n",
    "    previsionMN = modelMN.predict(testX)\n",
    "    previsionDT = modelDT.predict(testX)\n",
    "    previsionRF = modelRF.predict(testX)\n",
    "    previsionAB = modelAB.predict(testX)\n",
    "\n",
    "    #Calcula os resultados para o Multinomial Naive Bayes\n",
    "    metricsMN['accuracy'] += accuracy_score(testY, previsionMN)\n",
    "    metricsMN['precision'] += precision_score(testY, previsionMN)\n",
    "    metricsMN['recall'] += recall_score(testY, previsionMN)\n",
    "\n",
    "    #Calcula os resultados para o Decision Tree\n",
    "    metricsDT['accuracy'] += accuracy_score(testY, previsionDT)\n",
    "    metricsDT['precision'] += precision_score(testY, previsionDT)\n",
    "    metricsDT['recall'] += recall_score(testY, previsionDT)\n",
    "\n",
    "    #Calcula os resultados para o Random Forest\n",
    "    metricsRF['accuracy'] += accuracy_score(testY, previsionRF)\n",
    "    metricsRF['precision'] += precision_score(testY, previsionRF)\n",
    "    metricsRF['recall'] += recall_score(testY, previsionRF)\n",
    "\n",
    "    #Calcula os resultados para o Adaptive Boosting\n",
    "    metricsAB['accuracy'] += accuracy_score(testY, previsionAB)\n",
    "    metricsAB['precision'] += precision_score(testY, previsionAB)\n",
    "    metricsAB['recall'] += recall_score(testY, previsionAB)\n",
    "\n",
    "\n",
    "#Tirando a média dos Resultados Métricos\n",
    "metricsMN['accuracy'] /= nK\n",
    "metricsMN['precision'] /= nK\n",
    "metricsMN['recall'] /= nK\n",
    "\n",
    "metricsDT['accuracy'] /= nK\n",
    "metricsDT['precision'] /= nK\n",
    "metricsDT['recall'] /= nK\n",
    "\n",
    "metricsRF['accuracy'] /= nK\n",
    "metricsRF['precision'] /= nK\n",
    "metricsRF['recall'] /= nK\n",
    "\n",
    "metricsAB['accuracy'] /= nK\n",
    "metricsAB['precision'] /= nK\n",
    "metricsAB['recall'] /= nK"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3- Exportando Resultados\n",
    "\n",
    "Exportar todos os resultados para arquivo .CSV de melhor interpretação e apresentação de valores utilizando um editor de Planilhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = open('Parte 3 - Resultados.csv', 'w')\n",
    "\n",
    "csv.write('Algoritmos;Métricas Bootstrap')\n",
    "csv.write('\\n;Acurácia;Precisão;Sensibilidade')\n",
    "\n",
    "csv.write(\"\\nMultinomial NB;%.4f;%.4f;%.4f\" %(metricsMN['accuracy'], metricsMN['precision'], metricsMN['recall']))\n",
    "\n",
    "csv.write(\"\\nDecision Tree;%.4f;%.4f;%.4f\" %(metricsDT['accuracy'], metricsDT['precision'], metricsDT['recall']))\n",
    "\n",
    "csv.write(\"\\nRandom Forest;%.4f;%.4f;%.4f\" %(metricsRF['accuracy'], metricsRF['precision'], metricsRF['recall']))\n",
    "\n",
    "csv.write(\"\\nAdaptive Boosting;%.4f;%.4f;%.4f\" %(metricsAB['accuracy'], metricsAB['precision'], metricsAB['recall']))"
   ]
  }
 ]
}