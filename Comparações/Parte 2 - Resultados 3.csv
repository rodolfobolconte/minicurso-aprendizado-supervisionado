Algoritmos;Métricas Bootstrap;;;;;Métricas Holdout;;;;
;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade;[VN FP];[FN VP];Acurácia;Precisão;Sensibilidade
Multinomial NB;[22 49];[39 84];0.5464;0.6316;0.6829;[22 49];[39 84];0.5567;0.6383;0.7200
Decision Tree;[12 59];[43 80];0.4742;0.5755;0.6504;[12 59];[43 80];0.4639;0.5868;0.5680
Random Forest;[23 48];[50 73];0.4948;0.6033;0.5935;[23 48];[50 73];0.5052;0.6160;0.6160
Adaptive Boosting;[23 48];[52 71];0.4845;0.5966;0.5772;[23 48];[52 71];0.5567;0.6383;0.7200
;;;;;;;;;;
;;;;;;;;;;
;;;;;;;;;;
#Modelos Multinomial Naive Bayes para serem utilizandos com Reamostragem Holdout e Bootstrap;;;;;;;;;;
alpha = 0;;;;;;;;;;
fit_prior = False;;;;;;;;;;
class_prior = [0.5, 1];;;;;;;;;;
modelMNHT = MultinomialNB(alpha=alpha,;;;;;;;;;;
                          fit_prior=fit_prior,;;;;;;;;;;
                          class_prior=class_prior);;;;;;;;;;
modelMNBT = MultinomialNB(alpha=alpha,;;;;;;;;;;
                          fit_prior=fit_prior,;;;;;;;;;;
                          class_prior=class_prior);;;;;;;;;;
;;;;;;;;;;
#Modelos Decision Tree para serem utilizandos com Reamostragem Holdout e Bootstrap;;;;;;;;;;
criterion = 'entropy' #'gini' ou 'entropy';;;;;;;;;;
splitter = 'random' #'best' ou 'random';;;;;;;;;;
max_depth = 8;;;;;;;;;;
min_samples_split = 6;;;;;;;;;;
min_samples_leaf = 4;;;;;;;;;;
max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None;;;;;;;;;;
max_leaf_nodes = 12;;;;;;;;;;
modelDTHT = DecisionTreeClassifier(criterion=criterion,;;;;;;;;;;
                                   splitter=splitter,;;;;;;;;;;
                                   max_depth=max_depth,;;;;;;;;;;
                                   min_samples_split=min_samples_split,;;;;;;;;;;
                                   min_samples_leaf=min_samples_leaf,;;;;;;;;;;
                                   max_features=max_features,;;;;;;;;;;
                                   max_leaf_nodes=max_leaf_nodes);;;;;;;;;;
modelDTBT = DecisionTreeClassifier(criterion=criterion,;;;;;;;;;;
                                   splitter=splitter,;;;;;;;;;;
                                   max_depth=max_depth,;;;;;;;;;;
                                   min_samples_split=min_samples_split,;;;;;;;;;;
                                   min_samples_leaf=min_samples_leaf,;;;;;;;;;;
                                   max_features=max_features,;;;;;;;;;;
                                   max_leaf_nodes=max_leaf_nodes);;;;;;;;;;
;;;;;;;;;;
#Modelos Random Forest para serem utilizandos com Reamostragem Holdout e Bootstrap;;;;;;;;;;
n_estimators = 150;;;;;;;;;;
criterion = 'entropy' #'gini' ou 'entropy';;;;;;;;;;
max_depth = 8;;;;;;;;;;
min_samples_split = 6;;;;;;;;;;
min_samples_leaf = 4;;;;;;;;;;
max_features = 'log2' #'auto' == 'sqrt' ou 'log2' ou None;;;;;;;;;;
max_leaf_nodes = 12;;;;;;;;;;
bootstrap = False;;;;;;;;;;
max_samples = 0.75 #intervalo entre 0 e 1;;;;;;;;;;
modelRFHT = RandomForestClassifier(n_estimators=n_estimators,;;;;;;;;;;
                                   criterion=criterion,;;;;;;;;;;
                                   max_depth=max_depth,;;;;;;;;;;
                                   min_samples_split=min_samples_split,;;;;;;;;;;
                                   min_samples_leaf=min_samples_leaf,;;;;;;;;;;
                                   max_features=max_features,;;;;;;;;;;
                                   max_leaf_nodes=max_leaf_nodes,;;;;;;;;;;
                                   bootstrap=bootstrap,;;;;;;;;;;
                                   max_samples=max_samples);;;;;;;;;;
modelRFBT = RandomForestClassifier(n_estimators=n_estimators,;;;;;;;;;;
                                   criterion=criterion,;;;;;;;;;;
                                   max_depth=max_depth,;;;;;;;;;;
                                   min_samples_split=min_samples_split,;;;;;;;;;;
                                   min_samples_leaf=min_samples_leaf,;;;;;;;;;;
                                   max_features=max_features,;;;;;;;;;;
                                   max_leaf_nodes=max_leaf_nodes,;;;;;;;;;;
                                   bootstrap=bootstrap,;;;;;;;;;;
                                   max_samples=max_samples);;;;;;;;;;
;;;;;;;;;;
#Modelos Adaptive Boosting para serem utilizandos com Reamostragem Holdout e Bootstrap;;;;;;;;;;
base_estimator = None;;;;;;;;;;
n_estimators = 150;;;;;;;;;;
learning_rate = 10;;;;;;;;;;
algorithm = 'SAMME' # 'SAMME.R' ou 'SAMME';;;;;;;;;;
modelABHT = AdaBoostClassifier(base_estimator=base_estimator,;;;;;;;;;;
                               n_estimators=n_estimators,;;;;;;;;;;
                               learning_rate=learning_rate,;;;;;;;;;;
                               algorithm=algorithm,;;;;;;;;;;
                               random_state=random_state);;;;;;;;;;
modelABBT = AdaBoostClassifier(base_estimator=base_estimator,;;;;;;;;;;
                               n_estimators=n_estimators,;;;;;;;;;;
                               learning_rate=learning_rate,;;;;;;;;;;
                               algorithm=algorithm,;;;;;;;;;;
                               random_state=random_state);;;;;;;;;;
